{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e871e-aac9-4b74-b1e1-984a9df5eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80bc351-a8c3-47fa-83c6-89c024658586",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NFL ###\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Initialize the Chrome WebDriver with the options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "url = 'https://data.vsin.com/nfl/vegas-odds-linetracker/'\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait for the table to be present\n",
    "    table_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table'\n",
    "    table = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.XPATH, table_xpath))\n",
    "    )\n",
    "\n",
    "    # Get all immediate child elements of the table (both thead and tbody)\n",
    "    table_children = table.find_elements(By.XPATH, './*')\n",
    "\n",
    "    # Initialize an empty list to hold all rows of data\n",
    "    data = []\n",
    "\n",
    "    # Initialize current column names as empty\n",
    "    column_names = []\n",
    "\n",
    "    # Iterate over each child element of the table\n",
    "    for child in table_children:\n",
    "        if child.tag_name.lower() == 'thead':\n",
    "            # Extract column names from the header row\n",
    "            header_cells = child.find_elements(By.XPATH, './tr/th')\n",
    "            column_names = [cell.text.strip() for cell in header_cells]\n",
    "            # Handle empty header names\n",
    "            column_names = [name if name else f\"Column{index+1}\" for index, name in enumerate(column_names)]\n",
    "        elif child.tag_name.lower() == 'tbody':\n",
    "            # Use the current column names to extract data\n",
    "            rows = child.find_elements(By.TAG_NAME, \"tr\")\n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                cell_data = [cell.text.strip() for cell in cells]\n",
    "                # Only add row if there is data\n",
    "                if cell_data:\n",
    "                    # Match the number of columns in data with column names\n",
    "                    if len(cell_data) != len(column_names):\n",
    "                        # Adjust cell_data or column_names if necessary\n",
    "                        max_length = max(len(cell_data), len(column_names))\n",
    "                        cell_data.extend([None] * (max_length - len(cell_data)))\n",
    "                        column_names.extend([f\"ExtraColumn{index+1}\" for index in range(len(column_names), max_length)])\n",
    "                    # Create a dictionary using column names as keys\n",
    "                    row_data = {column_names[index]: value for index, value in enumerate(cell_data)}\n",
    "                    data.append(row_data)\n",
    "        else:\n",
    "            # Other types of elements, skip or handle if needed\n",
    "            pass\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "# Generate a timestamp\n",
    "current_time = datetime.datetime.now()\n",
    "# timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# timestamp = current_time.strftime(\"%Y%m%d_%H%M\")\n",
    "timestamp = current_time.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Write the data to a JSON file with timestamp in the filename\n",
    "filename = f'data/nfl_odds_vsin_{timestamp}.json'\n",
    "with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Data has been saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063f542-07c2-41da-95db-9f71289bb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file from the data directory\n",
    "with open('data/nfl_odds_vsin_20240926_1357.json') as f:\n",
    "    games = json.load(f)\n",
    "\n",
    "# Function to print detailed game information in one line for each sportsbook\n",
    "def print_game_info(game):\n",
    "    # Extract the second column name (day and matchup)\n",
    "    day_and_matchup = list(game.keys())[1]  # Extract the second column name (which contains the date)\n",
    "    teams = game[day_and_matchup].replace('\\n', ' ').replace('Splits', '').strip()  # Remove \"Splits\" from the teams\n",
    "    game_time = game['Time'].replace('Splits', '').replace('\\n', '').strip()\n",
    "    print(f\"Game Day: {day_and_matchup} | Game Time: {game_time}\")\n",
    "    print(f\"Matchup: {teams}\\n\")\n",
    "    \n",
    "    for sportsbook, line in game.items():\n",
    "        if sportsbook not in [\"Time\", day_and_matchup]:  # Exclude time and matchup keys\n",
    "            # Combine the sportsbook and its line into one line\n",
    "            print(f\"\\033[1m{sportsbook}:\\033[0m {line.replace('\\n', ' ')}\")\n",
    "    print('-' * 50)\n",
    "\n",
    "for game in games[:]:\n",
    "    print_game_info(game)\n",
    "\n",
    "# # Print the first 3 games\n",
    "# print(\"First 3 Games:\")\n",
    "# for game in games[:3]:\n",
    "#     print_game_info(game)\n",
    "\n",
    "# # Print the last 3 games\n",
    "# print(\"\\nLast 3 Games:\")\n",
    "# for game in games[-3:]:\n",
    "#     print_game_info(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475df21b-2fa1-412e-8e04-377e025ab284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68737277-2f4a-4993-a781-1248f49980f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c812ee-abde-4ff0-a8c0-a9309167ab7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333d496-4c0d-4b3a-823e-3f9f827141a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a9ad2-f44a-491b-8536-89b47e5711ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b967e7d-dd03-4e5a-b2df-5eb68abbb9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5083284-43a5-415b-9813-350147b4ba07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5279057-b7fd-47e3-98ee-c1a82bb0c4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48511b4-d3be-4aa3-a4f5-b7bb1177fcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fe040-38d7-41d6-bc0b-a49d6f9b95b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219d882-cfb5-4e66-9391-30a3150ade44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Initialize the Chrome WebDriver with the options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "# url = 'https://data.vsin.com/vegas-odds-linetracker/'\n",
    "url = 'https://data.vsin.com/nfl/vegas-odds-linetracker/'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Locate the table body using XPath\n",
    "tbody_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody[1]'\n",
    "tbody_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody[2]'\n",
    "tbody_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody[3]'\n",
    "tbody_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody[4]'\n",
    "tbody_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody[5]'\n",
    "tbody = driver.find_element(By.XPATH, tbody_xpath)\n",
    "\n",
    "# Initialize an empty list to hold all rows of data\n",
    "data = []\n",
    "\n",
    "# Extract data from each row\n",
    "rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    cell_data = [cell.text for cell in cells]\n",
    "    row_data = {'Column{}'.format(index+1): value for index, value in enumerate(cell_data)}\n",
    "    data.append(row_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Generate a timestamp\n",
    "current_time = datetime.datetime.now()\n",
    "timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Write the data to a JSON file with timestamp in the filename\n",
    "filename = f'output_data_{timestamp}.json'\n",
    "with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1159a-7c7e-4691-a075-20a3f2697098",
   "metadata": {},
   "outputs": [],
   "source": [
    "/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]\n",
    "/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody[1]\n",
    "/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4a58c-ceaa-4cc2-92b3-830a8c485d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Initialize the Chrome WebDriver with the options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "url = 'https://data.vsin.com/nfl/vegas-odds-linetracker/'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Initialize an empty list to hold all rows of data\n",
    "data = []\n",
    "\n",
    "# Locate all tbody elements using XPath\n",
    "tbody_list = driver.find_elements(By.XPATH, '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table/tbody')\n",
    "\n",
    "# Iterate over each tbody element\n",
    "for tbody in tbody_list:\n",
    "    # Extract data from each row in the current tbody\n",
    "    rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        cell_data = [cell.text for cell in cells]\n",
    "        row_data = {'Column{}'.format(index+1): value for index, value in enumerate(cell_data)}\n",
    "        data.append(row_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Generate a timestamp\n",
    "current_time = datetime.datetime.now()\n",
    "timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Write the data to a JSON file with timestamp in the filename\n",
    "filename = f'output_data_{timestamp}.json'\n",
    "with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ccbc0-17a8-425a-b903-6a7017b37b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4785c7-8bd0-44f4-969b-04a4eff2556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Initialize the Chrome WebDriver with the options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "url = 'https://data.vsin.com/nfl/vegas-odds-linetracker/'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the table to be present\n",
    "table_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table'\n",
    "table = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, table_xpath))\n",
    ")\n",
    "\n",
    "# Extract column names from the header row\n",
    "header_xpath = table_xpath + '/thead[1]/tr'\n",
    "header_row = driver.find_element(By.XPATH, header_xpath)\n",
    "header_cells = header_row.find_elements(By.TAG_NAME, 'th')\n",
    "column_names = [cell.text.strip() for cell in header_cells]\n",
    "\n",
    "# Handle cases where headers are empty or have special characters\n",
    "column_names = [name if name else f\"Column{index+1}\" for index, name in enumerate(column_names)]\n",
    "\n",
    "# Find all tbody elements within the table\n",
    "tbodies = table.find_elements(By.TAG_NAME, 'tbody')\n",
    "\n",
    "# Initialize an empty list to hold all rows of data\n",
    "data = []\n",
    "\n",
    "# Iterate over each tbody and extract data\n",
    "for tbody in tbodies:\n",
    "    rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        cell_data = [cell.text.strip() for cell in cells]\n",
    "        # Only add row if there is data\n",
    "        if cell_data:\n",
    "            # Match the number of columns in data with column names\n",
    "            if len(cell_data) != len(column_names):\n",
    "                # Adjust cell_data or column_names if necessary\n",
    "                # Here, we'll pad the shorter list with None\n",
    "                max_length = max(len(cell_data), len(column_names))\n",
    "                cell_data.extend([None] * (max_length - len(cell_data)))\n",
    "                column_names.extend([f\"ExtraColumn{index+1}\" for index in range(len(column_names), max_length)])\n",
    "            # Create a dictionary using column names as keys\n",
    "            row_data = {column_names[index]: value for index, value in enumerate(cell_data)}\n",
    "            data.append(row_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Generate a timestamp\n",
    "current_time = datetime.datetime.now()\n",
    "timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Write the data to a JSON file with timestamp in the filename\n",
    "filename = f'output_data_{timestamp}.json'\n",
    "with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Data has been saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4146a4e3-7f6e-4d27-bb44-6c7d6e1d4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "\n",
    "# Initialize the Chrome WebDriver with the options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "url = 'https://data.vsin.com/nfl/vegas-odds-linetracker/'\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    # Wait for the table to be present\n",
    "    table_xpath = '/html/body/div[6]/div[2]/div/div[3]/div/div/div/div[2]/b/div[2]/table'\n",
    "    table = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.XPATH, table_xpath))\n",
    "    )\n",
    "\n",
    "    # Get all immediate child elements of the table (both thead and tbody)\n",
    "    table_children = table.find_elements(By.XPATH, './*')\n",
    "\n",
    "    # Initialize an empty list to hold all rows of data\n",
    "    data = []\n",
    "\n",
    "    # Initialize current column names as empty\n",
    "    column_names = []\n",
    "\n",
    "    # Iterate over each child element of the table\n",
    "    for child in table_children:\n",
    "        if child.tag_name.lower() == 'thead':\n",
    "            # Extract column names from the header row\n",
    "            header_cells = child.find_elements(By.XPATH, './tr/th')\n",
    "            column_names = [cell.text.strip() for cell in header_cells]\n",
    "            # Handle empty header names\n",
    "            column_names = [name if name else f\"Column{index+1}\" for index, name in enumerate(column_names)]\n",
    "        elif child.tag_name.lower() == 'tbody':\n",
    "            # Use the current column names to extract data\n",
    "            rows = child.find_elements(By.TAG_NAME, \"tr\")\n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                cell_data = [cell.text.strip() for cell in cells]\n",
    "                # Only add row if there is data\n",
    "                if cell_data:\n",
    "                    # Match the number of columns in data with column names\n",
    "                    if len(cell_data) != len(column_names):\n",
    "                        # Adjust cell_data or column_names if necessary\n",
    "                        max_length = max(len(cell_data), len(column_names))\n",
    "                        cell_data.extend([None] * (max_length - len(cell_data)))\n",
    "                        column_names.extend([f\"ExtraColumn{index+1}\" for index in range(len(column_names), max_length)])\n",
    "                    # Create a dictionary using column names as keys\n",
    "                    row_data = {column_names[index]: value for index, value in enumerate(cell_data)}\n",
    "                    data.append(row_data)\n",
    "        else:\n",
    "            # Other types of elements, skip or handle if needed\n",
    "            pass\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "# Generate a timestamp\n",
    "current_time = datetime.datetime.now()\n",
    "# timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# timestamp = current_time.strftime(\"%Y%m%d_%H%M\")\n",
    "timestamp = current_time.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Write the data to a JSON file with timestamp in the filename\n",
    "filename = f'data/nfl_odds_vsin_{timestamp}.json'\n",
    "with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Data has been saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ed269-0a92-47b5-80bf-04d5caf371d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31808232-8327-4f30-a9ab-6199ef2e9d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
